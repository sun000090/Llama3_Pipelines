{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dYqYtkTrJ4Li"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AEvMH0WWRh7k"
   },
   "outputs": [],
   "source": [
    "pip -q install langchain langchain-community langchain_groq sentence-transformers langchain-huggingface huggingface-hub faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-crXg6k5RFqg"
   },
   "source": [
    "### USING PICKLE FILE FOR CHAT HISTORY MANAGEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rLw1rHXFRjgx"
   },
   "outputs": [],
   "source": [
    "model_name ='llama3-8b-8192'\n",
    "groq_key ='key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ip69gxW8R8za"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationChain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TG0Cm9PySA8x"
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=model_name, groq_api_key=groq_key, temperature=0.5, max_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xiElJmzUWs4r"
   },
   "outputs": [],
   "source": [
    "session_id = 'sundeep_0'\n",
    "username = 'sun00009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "j_kekH4faUU7"
   },
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "CVBf4RJ7aSkE"
   },
   "outputs": [],
   "source": [
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "uujDtkW9bGGS"
   },
   "outputs": [],
   "source": [
    "template = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a helpful converastion chatbot. Keep your response to limit of 100 words only. Utilize the context if needed {context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "MPqurvl5bG8T"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_llm = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-BhpxCQkXxhg"
   },
   "outputs": [],
   "source": [
    "conversation = RunnableWithMessageHistory(\n",
    "    runnable=model_llm,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key='input',\n",
    "    history_messages_key='chat_history',\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=username,\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=session_id,\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "qM3_X_dYciEz",
    "outputId": "e51a8d27-f715-4fd9-c390-e893411be191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to listen and assist with any questions or topics you'd like to discuss.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'input':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "E5skW0xNY_fC",
    "outputId": "f9a2f4c6-db8f-4519-9cdc-a18ac829d5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi again! How's your day going so far?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'input':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "_gzAmjQ9c78a",
    "outputId": "28636849-8594-4ed1-f231-e21383b888b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi again! It seems like you're in a chatty mood! What's on your mind? Want to talk about something specific or just shoot the breeze? I'm all ears!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'input':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ipjz-SlIc_AQ",
    "outputId": "f8af6c04-f633-4a07-a479-a1d2f2a920ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi'), AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat? I'm here to listen and assist with any questions or topics you'd like to discuss.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 37, 'total_tokens': 80, 'completion_time': 0.03322573, 'prompt_time': 0.007854176, 'queue_time': None, 'total_time': 0.041079906}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'stop', 'logprobs': None}, id='run-fbb41cf5-c20b-47b1-ae58-63f0cda360fb-0', usage_metadata={'input_tokens': 37, 'output_tokens': 43, 'total_tokens': 80}), HumanMessage(content='Hi'), AIMessage(content=\"Hi again! How's your day going so far?\", response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 90, 'total_tokens': 102, 'completion_time': 0.009073979, 'prompt_time': 0.019118537, 'queue_time': None, 'total_time': 0.028192516}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-462b9aff-a9f7-4006-856f-727097fd6faa-0', usage_metadata={'input_tokens': 90, 'output_tokens': 12, 'total_tokens': 102}), HumanMessage(content='Hi'), AIMessage(content=\"Hi again! It seems like you're in a chatty mood! What's on your mind? Want to talk about something specific or just shoot the breeze? I'm all ears!\", response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 112, 'total_tokens': 150, 'completion_time': 0.030177814, 'prompt_time': 0.023289451, 'queue_time': None, 'total_time': 0.053467265}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'stop', 'logprobs': None}, id='run-5382def7-733c-4284-83d8-5627d2ac61ad-0', usage_metadata={'input_tokens': 112, 'output_tokens': 38, 'total_tokens': 150})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[username,session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7D6uMgrsB2qv"
   },
   "outputs": [],
   "source": [
    "# with open('chat_history.pkl', 'wb') as f:\n",
    "#     pickle.dump(store, f)\n",
    "\n",
    "# with open('chat_history.pkl', 'rb') as f:\n",
    "#     store = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CN41vPA5GyMn"
   },
   "source": [
    "### ADDING RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "G3REqQd0NAQm"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.schema.vectorstore import VectorStoreRetriever\n",
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "import huggingface_hub\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqqLJSLyf-rj",
    "outputId": "0dc89551-6b78-46fa-a627-1fff67a3aaff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "huggingface_hub.login(token='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "k1XZa5tkHdWA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2NjoNDZPHQqd"
   },
   "outputs": [],
   "source": [
    "text = DataFrameLoader(data_frame=df,page_content_column='page_content')\n",
    "documents = text.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Xd95XFKALGUn"
   },
   "outputs": [],
   "source": [
    "docs = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4314BtqLNmI",
    "outputId": "4b25cdce-8570-4476-a6f7-f726859e64a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EYXEat1DLps-"
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "L4rUnHEjNEsh"
   },
   "outputs": [],
   "source": [
    "# For redis\n",
    "# https://python.langchain.com/v0.2/docs/integrations/vectorstores/redis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cZ6ENLR0Muw2"
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4,\"fetch_k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "l6XFMxq7wvXQ"
   },
   "outputs": [],
   "source": [
    "context = itemgetter(\"input\") | retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "sbrEgFZqw2Jo"
   },
   "outputs": [],
   "source": [
    "first_step = RunnablePassthrough.assign(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "LajnziGQvoR5"
   },
   "outputs": [],
   "source": [
    "model_llm = first_step | prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "GUoLcKuEMxst"
   },
   "outputs": [],
   "source": [
    "rag_template = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given a chat history and the latest user question \"\n",
    "            \"which might reference context in the chat history, \"\n",
    "            \"formulate a standalone question which can be understood \"\n",
    "            \"without the chat history. Do NOT answer the question, \"\n",
    "            \"just reformulate it if needed and otherwise return it as is.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "rmvYwa7qNzGf"
   },
   "outputs": [],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_messages(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Hz027ICZN7zY"
   },
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm = model_llm,\n",
    "    retriever = retriever,\n",
    "    prompt = rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "K5KTqyJWOMjo"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "qGbjQ7DYQQPh"
   },
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm=model_llm, prompt=prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "yJ9xBxnFQfAO"
   },
   "outputs": [],
   "source": [
    "conversation_rag_chain = RunnableWithMessageHistory(\n",
    "    runnable=model_llm,\n",
    "    rag_chain=rag_chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key='input',\n",
    "    history_messages_key='chat_history',\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=username,\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=session_id,\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "L-JSFWqzQxz-",
    "outputId": "dffdcc25-05da-421b-c463-31ac34b0a47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat about something in particular?\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_rag_chain.invoke({'input':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "nFSOQfy4Q9e5",
    "outputId": "5fa4208a-c2a8-4956-bab7-ac77a6598d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get me some beer\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I'm just a chatbot, I don't have the ability to physically get you a beer. But I can certainly chat with you about it! What kind of beer are you in the mood for?\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_rag_chain.invoke({'input':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0EsHATVQ-Sl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
