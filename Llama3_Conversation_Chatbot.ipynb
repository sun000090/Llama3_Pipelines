{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYqYtkTrJ4Li"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEvMH0WWRh7k",
    "outputId": "bbd84cca-3ee0-4420-e976-fff50e8c0986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "pip -q install langchain langchain-community langchain_groq huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-crXg6k5RFqg"
   },
   "source": [
    "### USING PICKLE FILE FOR CHAT HISTORY MANAGEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLw1rHXFRjgx"
   },
   "outputs": [],
   "source": [
    "model_name ='llama3-8b-8192'\n",
    "groq_key ='key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "Ip69gxW8R8za"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationChain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG0Cm9PySA8x"
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=model_name, groq_api_key=groq_key, temperature=0.5, max_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiElJmzUWs4r"
   },
   "outputs": [],
   "source": [
    "session_id = 'sundeep_0'\n",
    "username = 'sun00009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "j_kekH4faUU7"
   },
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "CVBf4RJ7aSkE"
   },
   "outputs": [],
   "source": [
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "uujDtkW9bGGS"
   },
   "outputs": [],
   "source": [
    "template = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a helpful converastion chatbot. Keep your response to limit of 100 words only.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "MPqurvl5bG8T"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "lJD1atSXbRgs"
   },
   "outputs": [],
   "source": [
    "model_llm = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "-BhpxCQkXxhg"
   },
   "outputs": [],
   "source": [
    "conversation = RunnableWithMessageHistory(\n",
    "    runnable=model_llm,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key='question',\n",
    "    history_messages_key='history',\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=username,\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=session_id,\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "qM3_X_dYciEz",
    "outputId": "4028ff28-ce7d-4bfa-861f-4f67a2dab9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hello! It seems like you're not saying anything. Is there something on your mind that you'd like to talk about or ask? I'm here to help with any questions or concerns you may have. I can also suggest some topics to discuss if you're feeling stuck. Just let me know how I can assist you!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'question':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "E5skW0xNY_fC",
    "outputId": "5cf54185-25a7-4a7e-8198-3121fce91c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something on your mind that you'd like to talk about or ask? I'm here to listen and help if I can.\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'question':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "_gzAmjQ9c78a",
    "outputId": "b419e738-9696-4464-ec59-27fa1bc059e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Hi again! It seems like we're just exchanging hellos. Is there something specific you'd like to talk about or ask? I'm here to listen and help if I can.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({'question':input()},\n",
    "                    config={\"configurable\": {\"user_id\": username, 'conversation_id': session_id}}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ipjz-SlIc_AQ",
    "outputId": "cef38436-00e8-4057-ffc4-b9f0d1b798f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content=''), AIMessage(content=\"Hello! It seems like you're not saying anything. Is there something on your mind that you'd like to talk about or ask? I'm here to help with any questions or concerns you may have. I can also suggest some topics to discuss if you're feeling stuck. Just let me know how I can assist you!\", response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 37, 'total_tokens': 103, 'completion_time': 0.05191208, 'prompt_time': 0.008296921, 'queue_time': None, 'total_time': 0.060209001}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'stop', 'logprobs': None}, id='run-27df7441-de81-4533-8f04-834a1550f33c-0', usage_metadata={'input_tokens': 37, 'output_tokens': 66, 'total_tokens': 103}), HumanMessage(content='Hi'), AIMessage(content=\"Hi! It's nice to meet you. Is there something on your mind that you'd like to talk about or ask? I'm here to listen and help if I can.\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 112, 'total_tokens': 149, 'completion_time': 0.028590908, 'prompt_time': 0.022811679, 'queue_time': None, 'total_time': 0.051402587}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf8984c6-854b-4f30-b51a-8ebdf162bb67-0', usage_metadata={'input_tokens': 112, 'output_tokens': 37, 'total_tokens': 149}), HumanMessage(content='Hi'), AIMessage(content=\"Hi again! It seems like we're just exchanging hellos. Is there something specific you'd like to talk about or ask? I'm here to listen and help if I can.\", response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 159, 'total_tokens': 197, 'completion_time': 0.029295754, 'prompt_time': 0.03207795, 'queue_time': None, 'total_time': 0.061373704}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_873a560973', 'finish_reason': 'stop', 'logprobs': None}, id='run-1411978b-79a8-4a7c-9fe3-486bcd184e0a-0', usage_metadata={'input_tokens': 159, 'output_tokens': 38, 'total_tokens': 197})])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[username,session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "7D6uMgrsB2qv"
   },
   "outputs": [],
   "source": [
    "# with open('chat_history.pkl', 'wb') as f:\n",
    "#     pickle.dump(store, f)\n",
    "\n",
    "# with open('chat_history.pkl', 'rb') as f:\n",
    "#     store = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3REqQd0NAQm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
